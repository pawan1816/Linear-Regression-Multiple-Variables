{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a8d4f7-5ba8-42de-ac36-1438182f9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# write a program to dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e897c6-1a69-4777-aac4-b2f11d83ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate entropy\n",
    "def entropy(data):\n",
    "    value_counts = data.value_counts()\n",
    "    total = len(data)\n",
    "    entropy_value = 0\n",
    "    for count in value_counts:\n",
    "        probability = count / total\n",
    "        entropy_value -= probability * math.log2(probability)\n",
    "    return entropy_value\n",
    "\n",
    "# Calculate Information Gain\n",
    "def information_gain(data, feature, target):\n",
    "    total_entropy = entropy(data[target])\n",
    "    feature_values = data[feature].value_counts()\n",
    "    \n",
    "    weighted_entropy = 0\n",
    "    for value in feature_values.index:\n",
    "        subset = data[data[feature] == value]\n",
    "        subset_entropy = entropy(subset[target])\n",
    "        weighted_entropy += (len(subset) / len(data)) * subset_entropy\n",
    "\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "# ID3 Algorithm to Build the Decision Tree\n",
    "def id3(data, features, target):\n",
    "    # If all records have the same target value, return that value\n",
    "    if len(data[target].unique()) == 1:\n",
    "        return data[target].iloc[0]\n",
    "    \n",
    "    # If no features are left, return the most frequent target value\n",
    "    if len(features) == 0:\n",
    "        return data[target].mode()[0]\n",
    "    \n",
    "    # Calculate information gain for all features\n",
    "    gains = {feature: information_gain(data, feature, target) for feature in features}\n",
    "    \n",
    "    # Select the feature with the highest information gain\n",
    "    best_feature = max(gains, key=gains.get)\n",
    "    \n",
    "    # Create a decision node with the best feature\n",
    "    tree = {best_feature: {}}\n",
    "    \n",
    "    # Recurse on the subsets of data split by the best feature\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        subtree = id3(subset, [feature for feature in features if feature != best_feature], target)\n",
    "        tree[best_feature][value] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "# Classify a new sample using the decision tree\n",
    "def classify(tree, sample):\n",
    "    if not isinstance(tree, dict):  # Leaf node (target class)\n",
    "        return tree\n",
    "    \n",
    "    feature = list(tree.keys())[0]\n",
    "    feature_value = sample[feature]\n",
    "    \n",
    "    if feature_value in tree[feature]:\n",
    "        return classify(tree[feature][feature_value], sample)\n",
    "    else:\n",
    "        return None  # Handle case where feature value is not present in the tree\n",
    "\n",
    "# Example Dataset (using the classic 'PlayTennis' dataset)\n",
    "data = pd.DataFrame({\n",
    "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy'],\n",
    "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild', 'Mild', 'Mild'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'High', 'Low', 'Low', 'High', 'Low', 'Low', 'Low', 'Low', 'High', 'High'],\n",
    "    'Windy': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Weak', 'Strong', 'Weak', 'Weak', 'Strong', 'Weak', 'Strong', 'Weak', 'Strong'],\n",
    "    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "# Features and Target\n",
    "features = ['Outlook', 'Temperature', 'Humidity', 'Windy']\n",
    "target = 'PlayTennis'\n",
    "\n",
    "# Build the Decision Tree\n",
    "tree = id3(data, features, target)\n",
    "\n",
    "# Display the Decision Tree\n",
    "print(\"Decision Tree:\")\n",
    "print(tree)\n",
    "\n",
    "# Classify a new sample\n",
    "new_sample = {'Outlook': 'Sunny', 'Temperature': 'Hot', 'Humidity': 'High', 'Windy': 'Weak'}\n",
    "result = classify(tree, new_sample)\n",
    "\n",
    "print(\"\\nClassification Result for New Sample:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d744b-f873-4b2b-b441-f7d50074c94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
